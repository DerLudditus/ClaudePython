<!DOCTYPE html>
<html lang="en"><head><meta charset="utf-8"/><title>How to create a dataframe in Python</title>
<link rel="preconnect" href="https://fonts.googleapis.com" />
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous" />
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@700&amp;family=Literata:wght@400;700&amp;family=Fira+Code:wght@400;700&amp;display=swap" rel="stylesheet" type="text/css" />
  <link href="styles.css" rel="stylesheet" type="text/css" />
</head><body id="top">
  <script src="script.js"></script>
<h1><a href="index.html">How to create a dataframe in Python</a></h1><div><div><div><p>Creating a DataFrame in Python empowers you to organize and analyze data effectively. The <code>pandas</code> library provides multiple methods to construct DataFrames, transforming raw data into structured tables for seamless data manipulation and analysis.</p><p>This guide covers essential techniques, practical tips, and real-world applications for DataFrame creation, with code examples developed using <a href="https://claude.ai/">Claude</a>, an AI assistant built by Anthropic.</p><h2>Basic dataframe creation with <code>pandas</code></h2><pre><code>import pandas as pd

df = pd.DataFrame({&#x27;Name&#x27;: [&#x27;Alice&#x27;, &#x27;Bob&#x27;, &#x27;Charlie&#x27;], &#x27;Age&#x27;: [25, 30, 35]})
print(df)</code></pre><pre><code>Name  Age
0    Alice   25
1      Bob   30
2  Charlie   35</code></pre><p>The <code>pd.DataFrame()</code> constructor transforms a Python dictionary into a structured table, where dictionary keys become column headers and values become the data rows. This approach provides a clean, intuitive way to create DataFrames from scratch, especially when working with small datasets or prototyping.</p><p>The dictionary format offers several advantages for DataFrame creation:</p><ul><li>Column names automatically map to their corresponding data values</li><li>Python lists within the dictionary naturally convert to DataFrame columns</li><li>The index automatically generates sequential numbers starting from 0</li></ul><p>This method excels at quick data organization but becomes less practical for larger datasets. For those cases, you'll want to explore methods like CSV imports or database connections.</p><h2>Common ways to create dataframes</h2><p>Building on the basic dictionary method, Python offers several powerful approaches to construct DataFramesâ€”from structured dictionaries to arrays that handle complex numerical data.</p><h3>Create from a dictionary of lists</h3><pre><code>import pandas as pd

data = {&#x27;Name&#x27;: [&#x27;Alice&#x27;, &#x27;Bob&#x27;, &#x27;Charlie&#x27;], &#x27;Score&#x27;: [85, 92, 78]}
df = pd.DataFrame(data)
print(df)</code></pre><pre><code>Name  Score
0    Alice     85
1      Bob     92
2  Charlie     78</code></pre><p>This method creates a DataFrame by passing a dictionary where each key represents a column name and its corresponding value is a list of data. The dictionary structure naturally maps to the DataFrame's tabular format, with <code>Name</code> and <code>Score</code> becoming column headers while their list values form the rows.</p><ul><li>Each list in the dictionary must have the same length to maintain data alignment</li><li>The index automatically generates as sequential numbers starting from 0</li><li>Column order in the DataFrame matches the dictionary's key order in Python 3.7+</li></ul><p>The <code>pd.DataFrame()</code> constructor handles the conversion seamlessly. It transforms the dictionary of lists into a structured table that's ready for data analysis and manipulation.</p><h3>Create from a list of dictionaries</h3><pre><code>import pandas as pd

data = [
    {&#x27;Name&#x27;: &#x27;Alice&#x27;, &#x27;Score&#x27;: 85},
    {&#x27;Name&#x27;: &#x27;Bob&#x27;, &#x27;Score&#x27;: 92},
    {&#x27;Name&#x27;: &#x27;Charlie&#x27;, &#x27;Score&#x27;: 78}
]
df = pd.DataFrame(data)
print(df)</code></pre><pre><code>Name  Score
0    Alice     85
1      Bob     92
2  Charlie     78</code></pre><p>This approach transforms a list of dictionaries into a DataFrame, where each dictionary represents a row of data. The keys become column names while their values populate the cells. <code>pd.DataFrame()</code> automatically aligns matching keys across dictionaries to create a consistent table structure.</p><ul><li>Each dictionary in the list can contain different keys. Pandas will create columns for all unique keys and fill missing values with <code>NaN</code></li><li>The row order in the DataFrame matches the order of dictionaries in the list</li><li>This method works well when your data naturally fits a row-oriented format or when processing JSON responses from APIs</li></ul><p>The resulting DataFrame maintains the same structure as other creation methods but offers more flexibility in handling varying data shapes and sources.</p><h3>Create from NumPy arrays</h3><pre><code>import pandas as pd
import numpy as np

data = np.array([[&#x27;Alice&#x27;, 85], [&#x27;Bob&#x27;, 92], [&#x27;Charlie&#x27;, 78]])
df = pd.DataFrame(data, columns=[&#x27;Name&#x27;, &#x27;Score&#x27;])
print(df)</code></pre><pre><code>Name Score
0    Alice    85
1      Bob    92
2  Charlie    78</code></pre><p>NumPy arrays provide a powerful foundation for DataFrame creation, especially when working with numerical data. The <code>pd.DataFrame()</code> constructor transforms a 2D array into a structured table, with each inner array becoming a row in the DataFrame.</p><ul><li>The <code>columns</code> parameter explicitly names your DataFrame columns, making the data more meaningful and easier to reference</li><li>NumPy arrays must maintain consistent data types within each column. This constraint ensures data integrity and optimizes memory usage</li><li>The array's shape determines the DataFrame dimensions. In this case, a 3x2 array creates 3 rows and 2 columns</li></ul><p>This method particularly shines when performing numerical computations or working with scientific data, as NumPy arrays offer superior performance for mathematical operations.</p><h2>Advanced dataframe creation techniques</h2><p>Building on the foundational methods, pandas offers sophisticated DataFrame creation techniques that unlock custom indexing, hierarchical data structures, and seamless integration with <code>Series</code> objects for more nuanced data organization.</p><h3>Create with custom index and column labels</h3><pre><code>import pandas as pd

data = [[85, 90], [92, 88], [78, 85]]
df = pd.DataFrame(data, 
                 index=[&#x27;Alice&#x27;, &#x27;Bob&#x27;, &#x27;Charlie&#x27;],
                 columns=[&#x27;Math&#x27;, &#x27;Science&#x27;])
print(df)</code></pre><pre><code>Math  Science
Alice     85       90
Bob       92       88
Charlie   78       85</code></pre><p>Custom indexing transforms how you reference and organize DataFrame data. The <code>index</code> parameter replaces default numeric indices with meaningful labels, while <code>columns</code> assigns names to each data column. This creates a more intuitive way to access specific values.</p><ul><li>The <code>data</code> parameter accepts a nested list where each inner list represents a row</li><li>Index labels must be unique and match the number of rows in your data</li><li>Column labels must match the number of values in each row</li></ul><p>This approach enables natural data access using descriptive labels. You can retrieve Bob's Math score with <code>df.loc['Bob', 'Math']</code> instead of relying on numeric positions.</p><h3>Create with multi-level indices</h3><pre><code>import pandas as pd
import numpy as np

index = pd.MultiIndex.from_tuples([(&#x27;A&#x27;, 1), (&#x27;A&#x27;, 2), (&#x27;B&#x27;, 1)], 
                                 names=[&#x27;Letter&#x27;, &#x27;Number&#x27;])
df = pd.DataFrame({&#x27;Value&#x27;: [0.1, 0.2, 0.3]}, index=index)
print(df)</code></pre><pre><code>Value
Letter Number      
A      1        0.1
       2        0.2
B      1        0.3</code></pre><p>Multi-level indices create hierarchical organization in your DataFrame, enabling more complex data relationships. The <code>MultiIndex.from_tuples()</code> function transforms tuple pairs into a two-tier index structure, with <code>Letter</code> as the primary level and <code>Number</code> as the secondary level.</p><ul><li>Each tuple in the index represents a unique combination of values (<code>'A'</code> pairs with both <code>1</code> and <code>2</code>)</li><li>The <code>names</code> parameter assigns labels to each index level for clearer data access</li><li>Values in the DataFrame align with their corresponding index pairs</li></ul><p>This structure proves invaluable when your data has natural hierarchies or requires grouping across multiple categories. You can access data using both levels, similar to how you'd navigate through nested dictionaries in Python.</p><h3>Create from a <code>Series</code> object</h3><pre><code>import pandas as pd

s = pd.Series([85, 92, 78], index=[&#x27;Alice&#x27;, &#x27;Bob&#x27;, &#x27;Charlie&#x27;], name=&#x27;Score&#x27;)
df = pd.DataFrame(s)
print(df)</code></pre><pre><code>Score
Alice      85
Bob        92
Charlie    78</code></pre><p>Converting a pandas <code>Series</code> to a DataFrame transforms a one-dimensional array into a structured table. The <code>Series</code> name becomes the column header while its index values form the row labels.</p><ul><li>The <code>name</code> parameter in the Series constructor defines the column name (<code>'Score'</code> in this case)</li><li>The <code>index</code> parameter creates meaningful row labels instead of default numeric indices</li><li>The resulting DataFrame maintains the original Series data organization but adds the flexibility of a two-dimensional structure</li></ul><p>This method works particularly well when you need to expand a single column of data into a more complex table structure. The DataFrame format opens up additional capabilities for data manipulation and analysis that aren't available with Series objects.</p><h3>Reading and analyzing sales data with <code>groupby</code></h3><p>The <code>groupby</code> operation transforms raw sales records into actionable insights by aggregating data based on shared characteristicsâ€”in this case, calculating total sales for each product category.</p><pre><code>import pandas as pd

sales_data = {&#x27;Product&#x27;: [&#x27;A&#x27;, &#x27;B&#x27;, &#x27;A&#x27;, &#x27;C&#x27;, &#x27;B&#x27;, &#x27;A&#x27;], 
              &#x27;Amount&#x27;: [100, 200, 150, 300, 250, 175]}
sales_df = pd.DataFrame(sales_data)
product_sales = sales_df.groupby(&#x27;Product&#x27;).sum()[&#x27;Amount&#x27;]
print(product_sales)</code></pre><p>This code demonstrates data aggregation using pandas' powerful grouping capabilities. The dictionary <code>sales_data</code> contains two lists: product identifiers (A, B, C) and their corresponding sales amounts. After converting this data into a DataFrame, <code>groupby('Product')</code> organizes the data by unique product values. The <code>sum()</code> function then calculates the total sales for each product.</p><ul><li>Product A's total combines 100 + 150 + 175</li><li>Product B's total adds 200 + 250</li><li>Product C represents a single sale of 300</li></ul><p>The final output displays each product's aggregated sales amount in a clean, indexed format.</p><h3>Merging datasets for customer segment analysis</h3><p>Combining customer profiles with transaction data through DataFrame merging enables precise analysis of purchasing patterns across different customer segments, revealing valuable insights about Premium and Standard tier behaviors.</p><pre><code>import pandas as pd

customers = pd.DataFrame({
    &#x27;CustomerID&#x27;: [1, 2, 3, 4],
    &#x27;Name&#x27;: [&#x27;Alice&#x27;, &#x27;Bob&#x27;, &#x27;Charlie&#x27;, &#x27;David&#x27;],
    &#x27;Segment&#x27;: [&#x27;Premium&#x27;, &#x27;Standard&#x27;, &#x27;Premium&#x27;, &#x27;Standard&#x27;]
})
orders = pd.DataFrame({
    &#x27;OrderID&#x27;: [101, 102, 103, 104, 105],
    &#x27;CustomerID&#x27;: [1, 3, 3, 2, 1],
    &#x27;Amount&#x27;: [150, 200, 300, 50, 100]
})
merged_data = pd.merge(orders, customers, on=&#x27;CustomerID&#x27;)
segment_analysis = merged_data.groupby(&#x27;Segment&#x27;)[&#x27;Amount&#x27;].agg([&#x27;sum&#x27;, &#x27;mean&#x27;])
print(segment_analysis)</code></pre><p>This code demonstrates data merging and aggregation in pandas. The first DataFrame stores customer profiles with their IDs, names, and segments. The second DataFrame contains order records with order IDs, customer IDs, and purchase amounts.</p><p>The <code>pd.merge()</code> function combines these DataFrames using <code>CustomerID</code> as the common key, creating a complete view of orders with customer details. Finally, <code>groupby('Segment')</code> organizes the data by customer segments while <code>agg(['sum', 'mean'])</code> calculates both total and average purchase amounts for each segment.</p><ul><li>Premium customers' total spending and average order value become clear</li><li>Standard tier purchasing patterns emerge from the aggregated data</li><li>The merged dataset connects individual transactions to customer segments</li></ul><h2>Common errors and challenges</h2><p>Creating DataFrames in Python requires careful attention to data types, column access methods, and handling missing valuesâ€”mastering these challenges unlocks pandas' full potential.</p><h3>Debugging type errors when accessing columns with <code>[]</code></h3><p>When accessing DataFrame columns containing spaces or special characters, the dot notation (<code>df.column</code>) often triggers type errors. The code below demonstrates this common pitfall where attempting to access <code>'First Name'</code> with dot notation fails. Python interprets the space as a syntax error.</p><pre><code>import pandas as pd

df = pd.DataFrame({&#x27;First Name&#x27;: [&#x27;Alice&#x27;, &#x27;Bob&#x27;, &#x27;Charlie&#x27;], 
                  &#x27;Age&#x27;: [25, 30, 35]})
# This will fail with an AttributeError
first_names = df.First Name
print(first_names)</code></pre><p>The dot notation fails because Python's syntax rules don't allow spaces in attribute names. When you try to access <code>df.First Name</code>, Python reads it as two separate terms instead of a single column identifier. The code below demonstrates the correct approach.</p><pre><code>import pandas as pd

df = pd.DataFrame({&#x27;First Name&#x27;: [&#x27;Alice&#x27;, &#x27;Bob&#x27;, &#x27;Charlie&#x27;], 
                  &#x27;Age&#x27;: [25, 30, 35]})
# Use bracket notation for column names with spaces
first_names = df[&#x27;First Name&#x27;]
print(first_names)</code></pre><p>The bracket notation <code>df['First Name']</code> provides a reliable way to access DataFrame columns containing spaces or special characters. While dot notation <code>df.column_name</code> works for simple column names, it fails when column names include spaces, hyphens, or other special characters.</p><ul><li>Always use brackets when column names contain spaces or special characters</li><li>Watch for this issue when working with imported data, especially CSV files where column headers often include spaces</li><li>The bracket notation accepts any valid string as a column name. This flexibility makes it the safer choice for column access</li></ul><p>Consider using consistent, Python-friendly column names in your data structures to avoid these access issues entirely. Underscores work well as space replacements.</p><h3>Fixing column data type issues with <code>astype()</code></h3><p>Numeric calculations in pandas require proper data type handling. When DataFrame columns contain strings that look like numbers, mathematical operations produce unexpected results. The code below demonstrates this common issue where multiplying string values leads to unintended behavior.</p><pre><code>import pandas as pd

data = {&#x27;ID&#x27;: [&#x27;1&#x27;, &#x27;2&#x27;, &#x27;3&#x27;], &#x27;Value&#x27;: [&#x27;100&#x27;, &#x27;200&#x27;, &#x27;300&#x27;]}
df = pd.DataFrame(data)
# This won&#x27;t give the expected result because &#x27;Value&#x27; is string type
result = df[&#x27;Value&#x27;] * 2
print(result)</code></pre><p>When multiplying <code>df['Value']</code> by 2, pandas concatenates the string twice instead of performing mathematical multiplication. The string data type prevents numeric operations. The following code demonstrates the proper solution.</p><pre><code>import pandas as pd

data = {&#x27;ID&#x27;: [&#x27;1&#x27;, &#x27;2&#x27;, &#x27;3&#x27;], &#x27;Value&#x27;: [&#x27;100&#x27;, &#x27;200&#x27;, &#x27;300&#x27;]}
df = pd.DataFrame(data)
# Convert &#x27;Value&#x27; column to integer before multiplication
df[&#x27;Value&#x27;] = df[&#x27;Value&#x27;].astype(int)
result = df[&#x27;Value&#x27;] * 2
print(result)</code></pre><p>The <code>astype()</code> function converts DataFrame columns to the correct data type for calculations. In the example, converting string values to integers with <code>astype(int)</code> enables proper multiplication instead of string concatenation.</p><ul><li>Watch for this issue when importing data from external sources like CSV files</li><li>Common data types include <code>int</code>, <code>float</code>, <code>str</code>, and <code>bool</code></li><li>Always verify column data types before performing mathematical operations</li></ul><p>This type conversion becomes especially important when working with financial data or performing calculations across multiple columns. Pandas automatically infers data types during DataFrame creation. However, explicit conversion often proves necessary for precise numerical operations.</p><h3>Resolving <code>NaN</code> values when merging with mismatched keys</h3><p>Merging DataFrames with mismatched keys often produces unexpected <code>NaN</code> values in the output. When key columns contain case differences or inconsistent formatting, pandas fails to match records correctly. Let's examine a common scenario where case sensitivity disrupts the merge operation.</p><pre><code>import pandas as pd

df1 = pd.DataFrame({&#x27;key&#x27;: [&#x27;A&#x27;, &#x27;B&#x27;, &#x27;C&#x27;], &#x27;value&#x27;: [1, 2, 3]})
df2 = pd.DataFrame({&#x27;key&#x27;: [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;], &#x27;value&#x27;: [4, 5, 6]})
# This will result in all NaN values due to case mismatch
merged = pd.merge(df1, df2, on=&#x27;key&#x27;)
print(merged)</code></pre><p>The merge fails because pandas treats uppercase and lowercase letters as distinct values. When <code>df1</code> contains uppercase keys and <code>df2</code> has lowercase keys, pandas can't match them. The following code demonstrates the proper solution.</p><pre><code>import pandas as pd

df1 = pd.DataFrame({&#x27;key&#x27;: [&#x27;A&#x27;, &#x27;B&#x27;, &#x27;C&#x27;], &#x27;value&#x27;: [1, 2, 3]})
df2 = pd.DataFrame({&#x27;key&#x27;: [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;], &#x27;value&#x27;: [4, 5, 6]})
# Convert keys to the same case before merging
df1[&#x27;key&#x27;] = df1[&#x27;key&#x27;].str.lower()
df2[&#x27;key&#x27;] = df2[&#x27;key&#x27;].str.lower()
merged = pd.merge(df1, df2, on=&#x27;key&#x27;, suffixes=(&#x27;_1&#x27;, &#x27;_2&#x27;))
print(merged)</code></pre><p>Converting keys to lowercase with <code>str.lower()</code> before merging ensures pandas can match records correctly. The <code>suffixes</code> parameter adds distinct identifiers to duplicate column names, preventing confusion in the merged DataFrame. This solution maintains data integrity while combining information from both sources.</p><p>Watch for case sensitivity issues when merging data from different sources. Common scenarios include:</p><ul><li>Importing data from multiple CSV files with inconsistent formatting</li><li>Combining user input data with database records</li><li>Working with APIs that return mixed-case responses</li></ul><p>Consider standardizing key columns early in your data pipeline to prevent these matching problems. String methods like <code>upper()</code>, <code>lower()</code>, or <code>strip()</code> help maintain consistent formatting.</p></div></div></div><h2>FAQs</h2><div><div><h3>What is the difference between a DataFrame and a Series in pandas?</h3><div><div><div><p>A <code>DataFrame</code> organizes data in a two-dimensional table with labeled rows and columns, similar to a spreadsheet. It excels at handling complex datasets where you need to analyze relationships between multiple variables.</p><p>In contrast, a <code>Series</code> is a one-dimensional array that holds a single column of data with an index. Think of it as one column from a <code>DataFrame</code>. You'll often use a <code>Series</code> when working with time-series data or performing calculations on a single variable.</p></div></div></div></div></div><div><div><h3>How do you check the data types of columns in a DataFrame?</h3><div><div><div><p>The <code>dtypes</code> attribute provides a quick overview of data types for all columns in your DataFrame. For more detailed insights, use <code>info()</code> to see both data types and non-null countsâ€”this helps identify potential data quality issues.</p><ul><li>Check individual columns with <code>df['column'].dtype</code></li><li>Use <code>select_dtypes()</code> to filter columns by their data types</li><li>Convert types using <code>astype()</code> when needed for analysis or memory optimization</li></ul><p>Understanding data types helps prevent calculation errors and ensures efficient memory usage in your data analysis workflow.</p></div></div></div></div></div><div><div><h3>Can you create a DataFrame from a dictionary with lists of different lengths?</h3><div><div><div><p>Yes, you can create a DataFrame from a dictionary with lists of different lengths. Pandas automatically handles this through a process called index alignment. When you pass a dictionary with uneven lists to <code>pd.DataFrame()</code>, Pandas fills missing values with <code>NaN</code> to ensure rectangular data structure.</p><p>This behavior makes Pandas flexible for real-world data scenarios where columns might have varying completeness. The DataFrame maintains data integrity by explicitly marking absent values instead of truncating or erroring out.</p></div></div></div></div></div><div><div><h3>What happens if you don&#x27;t specify column names when creating a DataFrame?</h3><div><div><div><p>When you skip column names in DataFrame creation, pandas automatically assigns numerical index labels starting from 0. This default behavior helps maintain data structure but can create challenges when you need to reference specific columns later.</p><p>The auto-generated names serve as temporary placeholders, following the pattern 0, 1, 2, and so on. While this works for quick data exploration, it's generally better to provide meaningful column names that describe your dataâ€”especially when sharing code or building data pipelines that others will maintain.</p></div></div></div></div></div><div><div><h3>How do you add a new column to an existing DataFrame after creation?</h3><div><div><div><p>Adding a new column to a DataFrame gives you flexibility to expand your data structure after creation. The simplest approach uses bracket notation with <code>df['new_column']</code> to define the column name, followed by an equals sign and your desired values. For more complex scenarios, you can use <code>assign()</code> to create columns based on other columns' values.</p><ul><li>Bracket notation works well for straightforward assignments and maintains readable code</li><li>The <code>assign()</code> method creates a new DataFrame copyâ€”ideal when you need to preserve the original</li><li>Both methods seamlessly integrate with pandas' vectorized operations for efficient data manipulation</li></ul></div></div></div></div></div></body></html>